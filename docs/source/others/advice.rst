机器学习的一些经验和建议
========================================
1. 评价模型时plot一下学习曲线,即可知道当前模型的状态(欠拟合?过拟合?完美?);

2. 在模型评价时常见的问题:

.. image:: ../images/advice_2.png
    :width: 500px
    :align: center

解决方法:

* bias:模型欠拟合

    - 提升模型拟合性能;

    - 增加模型训练迭代轮数;

    - 进一步特征工程,或增加更具相关性的特征数据;

* variance:模型过拟合

    - 增加正则化权重;

    - 增大样本量;

    - 减少模型训练迭代轮数(early stop);

    - 特征选择／降维

* data mismatch:训练集和测试集样本分布不同

    - 调整训练集和测试集的样本,可以让训练集包含测试集样本分布的数据。

3. 训练集,验证集和测试集必须来自同一分布,否则对模型准确度的判断会有很大的影响;

4. 任何影响到模型的数据,其预测出来的结果都无法真正代表模型的准确度。衡量模型的准确度必须使用那些在模型生成调优过程中从未使用过的数据集;

5. 验证集的样本容量通常在1000～10000;

6. 对于多评价准则问题,需要制定一个最优与满足平衡的策略。例如,一般来说准确率越高的的模型,所需要的计算时间越长。当需要同时考虑时间成本和准确度时,可以先设定一个时间上可以接受的最大值,在这个最大值范围内,选取准确率最高的模型;

7. 对训练结果进行人工误差分析,人工寻找被误分类的样本特征,可能会有新的启发;

8. 建模是个迭代的过程,有了大致的方向,就先建一个基模型,根据误差分析来改进模型。宁可要快速而不完美的开始,也不要过度思考。这也是为什么正确划分验证集和测试集,以及做误差分析的重要性;

.. image:: ../images/advice_1.png
    :width: 500px
    :align: center

9. 在没有足够的把握下和必需的条件下,最好不要手动离散化连续特征值,会影响模型准确度;

10. 特征决定了模型准确度的上限,而好的算法可以无限逼近这个上限。这也是很多时候调参的效果不及一个好特征的原因。一堆与目标值不相关的数据,再怎么调参优化也是没用的;





(to be continued...)